---
title: Analyzing single-cell RNA-seq data containing UMI counts
author: 
- name: Aaron T. L. Lun
  affiliation: &CRUK Cancer Research UK Cambridge Institute, Li Ka Shing Centre, Robinson Way, Cambridge CB2 0RE, United Kingdom
- name: Davis J. McCarthy
  affiliation: 
  - &EMBL EMBL European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, Cambridge CB10 1SD, United Kingdom
  - St Vincent's Institute of Medical Research, 41 Victoria Parade, Fitzroy, Victoria 3065, Australia
- name: John C. Marioni
  affiliation: 
  - *CRUK
  - *EMBL
  - Wellcome Trust Sanger Institute, Wellcome Genome Campus, Hinxton, Cambridge CB10 1SA, United Kingdom
- name: Bernd Jagla
  - affiliation:
  Pasteur Paris
  modified and adapted to the Pasteur Single Cell and beyond course by Bernd Jagla
date: "`r Sys.Date()`"
output: 
  BiocStyle::html_document:
    titlecaps: false
    toc_float: true
bibliography: ref.bib
---

```{r style, echo=FALSE, results='hide', message=FALSE, cache=FALSE}
library(BiocStyle)
library(knitr)
library(SingleCellExperiment)
library(scater)
library(org.Hs.eg.db)
library(scran)
library(BiocSingular)
opts_chunk$set(error=FALSE, message=FALSE, warning=FALSE, cache=TRUE)
opts_chunk$set(fig.asp=1)
```

# Overview

5k Peripheral blood mononuclear cells (PBMCs) from a healthy donor with cell surface proteins (v3 chemistry)
Single Cell Gene Expression Dataset by Cell Ranger 3.0.2
Peripheral blood mononuclear cells (PBMCs) from a healthy donor cells were stained with a panel of 31 TotalSeq™-B antibodies (BioLegend).

PBMCs are primary cells with relatively small amounts of RNA (~1pg RNA/cell).

Libraries were prepared following the Chromium Single Cell 3ʹ Reagent Kits v3 with Feature Barcoding technology for Cell Surface Protein User Guide (CG000185 RevB).

5,247 cells detected
Sequenced on Illumina NovaSeq with approximately 28,917 reads per cell
28bp read1 (16bp Chromium barcode and 12bp UMI), 91bp read2 (transcript), and 8bp I7 sample barcode
run with --expect-cells=5000


# load data

In case we haven't done so already.
This loads the object scEx into the working space/Environment.


```{r loaddata}
load("5k_pbmc_protein_v3_filtered_feature_bc_matrix.h5.RData")
```

# Quality control on the cells 

Here, we compute some quality control metrics with `r Biocpkg("scater")` [@mccarthy2017scater] to check whether the remaining cells are satisfactory.

```{r}


# Create some additional annotations
rowData(scEx)$featureType = "NA"
rowData(scEx)$featureType[grep("^MT",rownames(rowData(scEx)))] = "mito"
rowData(scEx)$featureType[grep("^RP",rownames(rowData(scEx)))] = "ribo"

# Adding Ensembl IDs.

ensembl <- mapIds(org.Hs.eg.db, keys=rownames(scEx), keytype="SYMBOL", column="ENSEMBL")



sce <- calculateQCMetrics(scEx, feature_controls=list(
    Mt=rowData(scEx)$featureType=="mito",
    Rt=rowData(scEx)$featureType=="ribo"))
rowData(sce)$ENSEMBL <- ensembl

```

We examine the distribution of the QC metrics across all cells (Figure \@ref(fig:libplotbrain)).
The library sizes here are at least one order of magnitude lower than observed in the 416B dataset.
This is consistent with the use of UMI counts rather than read counts, as each transcript molecule can only produce one UMI count but can yield many reads after fragmentation.
In addition, the spike-in proportions are more variable than observed in the 416B dataset.
This may reflect a greater variability in the total amount of endogenous RNA per cell when many cell types are present.

```{r libplotbrain, fig.wide=TRUE, fig.cap="Histograms of QC metrics including the library sizes, number of expressed genes and proportion of UMIs assigned to spike-in transcripts or mitochondrial genes for all cells in the brain dataset."}
par(mfrow=c(2,2), mar=c(5.1, 4.1, 0.1, 0.1))
hist(sce$total_counts/1e3, xlab="Library sizes (thousands)", main="", 
    breaks=20, col="grey80", ylab="Number of cells")
hist(sce$total_features_by_counts, xlab="Number of expressed genes", main="", 
    breaks=20, col="grey80", ylab="Number of cells")
hist(sce$pct_counts_Rt, xlab="ribosomal proportion (%)",
    ylab="Number of cells", breaks=20, main="", col="grey80")
hist(sce$pct_counts_Mt, xlab="Mitochondrial proportion (%)", 
    ylab="Number of cells", breaks=20, main="", col="grey80")
```

We remove small outliers for the library size and the number of expressed features, and large outliers for the spike-in proportions.
Again, the presence of spike-in transcripts means that we do not have to use the mitochondrial proportions.

```{r}
libsize.drop <- isOutlier(sce$total_counts, nmads=3, type="lower", log=TRUE)
feature.drop <- isOutlier(sce$total_features_by_counts, nmads=3, type="lower", log=TRUE)

```

Removal of low-quality cells is then performed by combining the filters for all of the metrics.
The majority of cells are retained, which suggests that the original quality control procedures were generally adequate.

```{r}
sce <- sce[,!(libsize.drop | feature.drop)]
data.frame(ByLibSize=sum(libsize.drop), ByFeature=sum(feature.drop), 
    Remaining=ncol(sce))
```

We could improve our cell filtering procedure further by setting `batch` in `isOutlier` to one or more known factors, e.g., mouse/plate of origin.
As previously mentioned, this would avoid inflation of the MAD and improve power to remove low-quality cells.
However, for simplicity, we will not do this as sufficient quality control has already been performed.



# Examining gene-level metrics

Figure \@ref(fig:topgenebrain) shows the most highly expressed genes across the cell population .


```{r topgenebrain, fig.asp=1.2, fig.wide=TRUE, fig.cap="Percentage of total counts assigned to the top 50 most highly-abundant features in the brain dataset. For each feature, each bar represents the percentage assigned to that feature for a single cell, while the circle represents the average across all cells. Bars are coloured by the total number of expressed features in each cell, while circles are coloured according to whether the feature is labelled as a control feature."}
fontsize <- theme(axis.text=element_text(size=12), axis.title=element_text(size=16))
plotHighestExprs(sce, n=50) + fontsize
```

Gene abundance is quantified by computing the average count across all cells (Figure \@ref(fig:abhistbrain)).
As previously mentioned, the UMI count is generally lower than the read count.

```{r abhistbrain, fig.cap="Histogram of log-average counts for all genes in the brain dataset."}
ave.counts <- calcAverage(sce, use_size_factors=FALSE)
hist(log10(ave.counts), breaks=100, main="", col="grey",
    xlab=expression(Log[10]~"average count"))
```

We save the average counts into the `SingleCellExperiment` object for later use.
We also remove genes that have average counts of zero, as this means that they are not expressed in any cell.

```{r}
rowData(sce)$ave.count <- ave.counts
to.keep <- ave.counts > 0
sce <- sce[to.keep,]
summary(to.keep)
```


# Normalization of cell-specific biases

We normalize endogenous genes using the `computeSumFactors()` function with an additional pre-clustering step [@lun2016pooling].
Cells in each cluster are normalized separately, and the size factors are rescaled to be comparable across clusters.
This avoids the need to assume that most genes are non-DE across the entire population - only a non-DE majority is required between pairs of clusters.
Scaling is then performed to ensure that size factors of cells in different clusters are comparable.

- We use a average count threshold of 0.1 to define high-abundance genes to use during normalization.
This is lower than the default threshold of `min.mean=1`, reflecting the fact that UMI counts are generally smaller than read counts.
- We speed up clustering by performing fast dimensionality reduction and then clustering cells on the PCs.
This is the purpose of the `BSPARAM=` argument, which instructs `quickCluster()` to use a approximate algorithm for PCA^[Using methods from the `r CRANpkg("irlba")` package.].
The approximation relies on stochastic initialization so we need to set the random seed for reproducibility - see below for more detail.

```{r}

set.seed(1000)
clusters <- quickCluster(sce, BSPARAM=IrlbaParam())
sce <- computeSumFactors(sce, cluster=clusters, min.mean=0.1)
summary(sizeFactors(sce))
```

Compared to the 416B analysis, more scatter is observed around the trend between the total count and size factor for each cell (Figure \@ref(fig:normplotbrain)).
This is consistent with an increased amount of DE between cells of different types, which compromises the accuracy of library size normalization [@robinson2010scaling].
In contrast, the size factors are estimated based on median ratios and are more robust to the presence of DE between cells.

```{r normplotbrain, fig.cap="Size factors from pooling, plotted against library sizes for all cells in the brain dataset. Axes are shown on a log-scale."}
plot(sizeFactors(sce), sce$total_counts/1e3, log="xy",
    ylab="Library size (thousands)", xlab="Size factor")
```


Finally, normalized log-expression values are computed for each endogenous gene or spike-in transcript using the appropriate size factors.

```{r}
sce <- normalize(sce)
```

__Comments from Aaron:__

- Only a rough clustering is required to avoid pooling together very different cell types in `computeSumFactors()`.
This reduces the chance of violating the non-DE assumption that is made during any gene-based scaling normalization.
There is no need for precise clustering at this step, as we will not be interpreting the `clusters` at all, 
`computeSumFactors()` is robust to a moderate level of differential expression between cells in the same cluster, so careful definition of subclusters is not required.
That said, there does need to be sufficient cells in each cluster for pooling, which can be guaranteed with the `min.size=` argument in `quickCluster()`.
- Older versions of `quickCluster()` performed clustering based on rank correlations between cells.
The current version (with `use.ranks=FALSE`) uses graph-based clustering on principal components obtained from log-expression values.
This is faster and yields higher resolution clusters than before.
Nonetheless, the previous behaviour can be recovered by setting the arguments appropriately, see `?quickCluster` for more details.


# Modelling and removing technical noise

We model the technical noise by fitting a mean-variance trend to the spike-in transcripts with the `trendVar()` function.

```{r}
var.fit <- trendVar(sce, parametric=TRUE, loess.args=list(span=0.4), use.spikes=FALSE)
var.out <- decomposeVar(sce, var.fit)
```


```{r hvgplotbrain, fig.cap="Variance of normalized log-expression values against the mean for each gene, calculated across all cells in the brain dataset after blocking on the sex effect. The blue line represents the mean-dependent trend in the technical variance of the spike-in transcripts (also highlighted as red points)."}
plot(var.out$mean, var.out$total, pch=16, cex=0.6, xlab="Mean log-expression", 
    ylab="Variance of log-expression")
points(var.out$mean[isSpike(sce)], var.out$total[isSpike(sce)], col="red", pch=16)
curve(var.fit$trend(x), col="dodgerblue", add=TRUE, lwd=2)
```

We check the distribution of expression values for the genes with the largest biological components to ensure that they are not driven by outliers (Figure \@ref(fig:hvgvioplotbrain)).
Some tweaking of the `plotExpression` parameters is necessary to visualize a large number of cells.

```{r hvgvioplotbrain, fig.cap="Violin plots of normalized log-expression values for the top 10 HVGs in the brain dataset. For each gene, each point represents the log-expression value for an individual cell."}
chosen.genes <- order(var.out$bio, decreasing=TRUE)[1:10]
plotExpression(sce, rownames(var.out)[chosen.genes], 
    point_alpha=0.05, jitter_type="jitter") + fontsize
```

Finally, we use PCA to denoise the expression values, yielding a set of coordinates for each cell where the technical noise has been removed.
Setting `BSPARAM=IrlbaParam()` in `denoisePCA()` will perform an approximate singular value decomposition (SVD) using methods from the `r CRANpkg("irlba")` package.
This is much faster than the exact algorithm on large datasets without much loss of accuracy.
The approximate algorithm involves a random initialization so we set the seed to guarantee reproducibility.

```{r}
set.seed(1000)
sce <- denoisePCA(sce, technical=var.fit$trend, BSPARAM=IrlbaParam())
ncol(reducedDim(sce, "PCA"))
```

**Comments from Aaron:**

- The upper limit of PCs to retain in `denoisePCA()` is specified by the `max.rank=` argument.
This is set to 100 by default to ensure that the approximate SVD runs quickly.
A higher `max.rank` may be more appropriate for extremely heterogeneous populations, though the default setting is generally satisfactory for dimensionality reduction.


# Data exploration with dimensionality reduction

We perform dimensionality reduction on the denoised PCs to check if there is any substructure. 
Cells separate into clear clusters in the _t_-SNE plot [@van2008visualizing] in Figure \@ref(fig:tsneplotbrain), corresponding to distinct subpopulations.
This is consistent with the presence of multiple cell types in the diverse brain population.
We increase the perplexity to favour visualization of the overall structure at the expense of local scale.

```{r tsneplotbrain, fig.cap="_t_-SNE plots constructed from the denoised PCs of the brain dataset. Each point represents a cell and is coloured according to its expression of _Neurod6_ (left) or _Mog_ (right).", fig.width=12, fig.asp=0.5}
set.seed(1000)
sce <- runTSNE(sce, use_dimred="PCA", perplexity=50)
tsne1 <- plotTSNE(sce, colour_by="CD8a_TotalSeqB") + fontsize
tsne2 <- plotTSNE(sce, colour_by="Mog") + fontsize
multiplot(tsne1, tsne2, cols=2)
```

The PCA plot is less effective at separating cells into many different clusters (Figure \@ref(fig:pcaplotbrain)).
This is because the first two PCs are driven by strong differences between specific subpopulations, which reduces the resolution of more subtle differences between some of the other subpopulations.
Nonetheless, some substructure is still visible.

```{r pcaplotbrain, fig.cap="PCA plots constructed from the denoised PCs of the brain dataset. Each point represents a cell and is coloured according to its expression of the _Neurod6_ (left) or _Mog_ (right).", fig.width=12, fig.asp=0.5}
pca1 <- plotReducedDim(sce, use_dimred="PCA", colour_by="CD8a_TotalSeqB") + fontsize
pca2 <- plotReducedDim(sce, use_dimred="PCA", colour_by="CD3_TotalSeqB") + fontsize
multiplot(pca1, pca2, cols=2)
```

For both methods, we colour each cell based on the expression of a particular gene.
This is a useful strategy for visualizing changes in expression across the lower-dimensional space.
It can also be used to characterise each cluster if the selected genes are known markers for particular cell types.
For example, _Mog_ can be used to identify clusters corresponding to oligodendrocytes.


# Clustering cells into putative subpopulations

## Using graph-based clustering

The reduced dimension coordinates are used to cluster cells into putative subpopulations.
We do so by constructing a shared-nearest-neighbour graph [@xu2015identification], in which cells are the nodes and edges are formed between cells that share nearest neighbours.
Clusters are then defined as highly connected communities of cells within this graph, using methods from the `r CRANpkg("igraph")` package.
This is more efficient than forming a pairwise distance matrix for hierarchical clustering of large numbers of cells.

```{r}
snn.gr <- buildSNNGraph(sce, use.dimred="PCA")
cluster.out <- igraph::cluster_walktrap(snn.gr)
my.clusters <- cluster.out$membership
table(my.clusters)
```

We visualize the cluster assignments for all cells on the _t_-SNE plot in Figure \@ref(fig:tsneclusterbrain).
Adjacent cells are generally assigned to the same cluster, indicating that the clustering procedure was applied correctly.

```{r tsneclusterbrain, message=FALSE, fig.cap="_t_-SNE plot of the denoised PCs of the brain dataset. Each point represents a cell and is coloured according to its assigned cluster identity."}
sce$cluster <- factor(my.clusters)
plotTSNE(sce, colour_by="cluster") + fontsize
```


An alternative approach is to use graph-based visualizations such as force-directed layouts (Figure \@ref(fig:fdlbrain)).
These are appealing as they directly represent the relationships used during clustering.
However, convergence tends to be slow for large graphs, so some tinkering with `niter=` may be required to ensure that the results are stable. 

```{r fdlbrain, message=FALSE, fig.cap="Force-directed layout for the shared nearest-neighbour graph of the brain dataset. Each point represents a cell and is coloured according to its assigned cluster identity."}
set.seed(2000)
reducedDim(sce, "force") <- igraph::layout_with_fr(snn.gr, niter=5000)
plotReducedDim(sce, colour_by="cluster", use_dimred="force")
```

Very heterogeneous datasets may yield a few large clusters on the first round of clustering.
It can be useful to repeat the variance modelling, denoising and clustering using only the cells within each of the initial clusters.
This can be achieved by subsetting `sce` according to a particular level of `my.clusters`, and re-applying the relevant functions on the subset.
Doing so may focus on a different set of genes that define heterogeneity _within_ an initial cluster, as opposed to those that define differences _between_ the initial clusters.
This would allow fine-scale structure within each cluster to be explored at greater resolution^[Also see comments `r simpleSingleCell:::.link("var", "HVGs and the bias-variance trade-off", "here")`.].
For simplicity, though, we will only use the broad clusters corresponding to clear subpopulations in this workflow.

**Comments from Aaron:**

- Many different clustering methods are available in the `r CRANpkg("igraph")` package.
We find that the Walktrap algorithm is usually a good default choice [@yang2016comparative], though users are encouraged to experiment with different algorithms.
- Decreasing the number of neighbours `k` in `buildSNNGraph` will reduce the connectivity of the graph.
This will generally result in the formation of smaller clusters [@xu2015identification], which may be desirable if greater resolution is required.
- Notice that we do not run `library(igraph)`, but instead use `igraph::` to extract methods from the package. 
This is because `r CRANpkg("igraph")` contains a `normalize` method that will override its counterpart from `r Biocpkg("scater")`, resulting in some unusual bugs.

## Evaluating graph-based clusters

The modularity score provides a global measure of clustering performance for community detection methods.
Briefly, it compares the number of within-cluster edges to the expected number under a null model of random edges.
A high modularity score (approaching the maximum of 1) indicates that the detected clusters are enriched for internal edges, with relatively few edges between clusters.

```{r}
igraph::modularity(cluster.out)
```

We further investigate the clusters by examining the total weight of edges for each pair of clusters.
For each pair, the observed total weight is compared to what is expected under a null model, similar to the modularity calculation.
Most clusters contain more internal links than expected (Figure \@ref(fig:heatmodbrain)), while links between clusters are fewer than expected.
This indicates that we successfully clustered cells into highly-connected communities.

```{r heatmodbrain, fig.cap="Heatmap of the log~10~-ratio of the total weight between nodes in the same cluster or in different clusters, relative to the total weight expected under a null model of random links."}
mod.out <- clusterModularity(snn.gr, my.clusters, get.values=TRUE)
ratio <- mod.out$observed/mod.out$expected
lratio <- log10(ratio + 1)

library(pheatmap)
pheatmap(lratio, cluster_rows=FALSE, cluster_cols=FALSE, 
    color=colorRampPalette(c("white", "blue"))(100))
```

To summarize the relationships between clusters, we use the ratio of the observed and expected total weights to build a graph across clusters.
The cluster-based graph can be visualized using a force-directed layout to identify "clusters of clusters" that are highly interconnected. 
This is similar to the "graph abstraction" strategy proposed by @wolf2017graph.

```{r graphbrain, fig.cap="Force-directed layout showing the relationships between clusters based on the ratio of observed to expected total weights between nodes in different clusters. The thickness of the edge between a pair of clusters is proportional to the corresponding ratio."}
cluster.gr <- igraph::graph_from_adjacency_matrix(ratio, 
    mode="undirected", weighted=TRUE, diag=FALSE)
plot(cluster.gr, edge.width=igraph::E(cluster.gr)$weight*10)  
```

**Comments from Aaron:**

- We do not use the silhouette coefficient to assess clustering for large datasets.
This is because `cluster::silhouette` requires the construction of a distance matrix, which may not be feasible when many cells are involved.
- Technically, the modularity score is obtained by subtracting the observed from expected total weights. 
We use the ratio instead as this is guaranteed to be positive and does not exhibit differences in magnitude due to differences in the number of cells in each cluster.

# Detecting marker genes between subpopulations

```{r, echo=FALSE, results="hide"}
# Hidden variables for use in text or hidden chunks,
# to avoid the need for manual changes.
chosen.inter.cluster <- 4
chosen.inter.other <- 11
```

We use the `findMarkers` function with `direction="up"` to identify upregulated marker genes for each cluster.
As previously mentioned, we focus on upregulated genes as these can quickly provide positive identification of cell type in a heterogeneous population.
We examine the table for cluster `r chosen.inter.cluster`, in which log-fold changes are reported between cluster `r chosen.inter.cluster` and every other cluster.
The same output is provided for each cluster in order to identify genes that discriminate between clusters.

```{r, echo=FALSE, results="hide"}
old.digits <- options()$digits
options(digits=3)
```

```{r}
markers <- findMarkers(sce, my.clusters, direction="up")
marker.set <- markers[["4"]]
head(marker.set[,1:8], 10) # only first 8 columns, for brevity
```

```{r, echo=FALSE, results="hide"}
# Checking the cluster is what we wanted, along with its related cluster.
other.inter <- chosen.inter.other - 1
gad1 <- sapply(marker.set["NKG7",-(1:3)], sign)
stopifnot(gad1[other.inter]==-1)
stopifnot(all(gad1[-other.inter]==1))

gad2 <- sapply(marker.set["Gad2",-(1:3)], sign)
stopifnot(gad2[other.inter]==-1)
stopifnot(all(gad2[-other.inter]==1))

stopifnot(all(sapply(marker.set["Synpr",-(1:3)], sign)==1))

options(digits=old.digits)
```

Figure \@ref(fig:heatmapmarkerbrain) indicates that most of the top markers are strongly DE in cells of cluster `r chosen.inter.cluster` compared to some or all of the other clusters.
We can use these markers to identify cells from cluster `r chosen.inter.cluster` in validation studies with an independent population of cells.
A quick look at the markers suggest that cluster `r chosen.inter.cluster` represents interneurons based on expression of *Gad1* and *Slc6a1* [@zeng2012largescale],
differing from closely related cells in cluster `r chosen.inter.other` by virtue of high *Synpr* expression.

```{r heatmapmarkerbrain, fig.wide=TRUE, fig.cap=sprintf("Heatmap of mean-centred and normalized log-expression values for the top set of markers for cluster %i in the brain dataset. Column colours represent the cluster to which each cell is assigned, as indicated by the legend.", chosen.inter.cluster)}
top.markers <- rownames(marker.set)[marker.set$Top <= 10]
plotHeatmap(sce, features=top.markers, columns=order(my.clusters),
    colour_columns_by="cluster", cluster_cols=FALSE, 
    center=TRUE, symmetric=TRUE, zlim=c(-5, 5))
```

An alternative visualization approach is to plot the log-fold changes to all other clusters directly (Figure \@ref(fig:heatmaplfcbrain)).
This is more concise and is useful in situations involving many clusters that contain different numbers of cells.

```{r heatmaplfcbrain, fig.asp=1.5, fig.cap=sprintf("Heatmap of log-fold changes in expression for the top set of markers for cluster %i, compared to every other cluster in the brain data set.", chosen.inter.cluster)}
logFCs <- as.matrix(marker.set[1:50,-(1:3)])
colnames(logFCs) <- sub("logFC.", "", colnames(logFCs))

library(pheatmap)
max.lfc <- max(abs(range(logFCs)))
pheatmap(logFCs, breaks=seq(-5, 5, length.out=101))
```

We save the list of candidate marker genes for further examination, using compression to reduce the file size.

```{r}
gzout <- gzfile("brain_marker_1.tsv.gz", open="wb")
write.table(marker.set, file=gzout, sep="\t", quote=FALSE, col.names=NA)
close(gzout)
```

**Comments from Aaron:**

- The `overlapExprs()` function may also be useful for summarizing differences between clusters.
This is discussed in more detail `r simpleSingleCell:::.link("de", "Using the Wilcoxon rank sum test", "here")`.

# Concluding remarks

Having completed the basic analysis, we save the `SingleCellExperiment` object with its associated data to file.
This is especially important here as the brain dataset is quite large.
If further analyses are to be performed, it would be inconvenient to have to repeat all of the pre-processing steps described above.

```{r}
saveRDS(file="brain_data.rds", sce)
```

```{r, echo=FALSE, results='hide'}
gc()
```

All software packages used in this workflow are publicly available from the Comprehensive R Archive Network (https://cran.r-project.org) or the Bioconductor project (http://bioconductor.org).
The specific version numbers of the packages used are shown below, along with the version of the R installation.

```{r}
sessionInfo()
```

# References

